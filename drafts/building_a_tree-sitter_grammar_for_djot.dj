---
title: "Building a tree-sitter grammar for Djot"
tags: ["Tag1", "Tag2"]
---

# Our subset

1. Paragraphs
1. Divs
1. Emphasis

```djot
This is a paragraph

::: some-class
This is inside a div
:::

This uses _emphasis_
```

# A first parser

- Simple paragraphs
- Newlines
- Text
- Emphasis
- Div

# External scanner

There are some issues with our div implementation:

1. There can be an arbitrary number of `:`, allowing divs to be nested.
1. Closing a div should close the paragraph.

While we could work around the varying levels of `:` with something hacky like this:

```js
div: ($) => choice($._div3, $._div4, $._div5, $._div6, $._div7, $._div8),
_div3: ($) => seq(/:{3}/, $._inside_div, /:{3}/),
_div4: ($) => seq(/:{4}/, $._inside_div, /:{4}/),
_div5: ($) => seq(/:{5}/, $._inside_div, /:{5}/), _div6: ($) => seq(/:{6}/, $._inside_div, /:{6}/),
_div7: ($) => seq(/:{7}/, $._inside_div, /:{7}/),
_div8: ($) => seq(/:{8}/, $._inside_div, /:{8}/),
_inside_div: ($) =>
  prec.left(seq(/[ ]*/, optional($.class_name), "\n", repeat($._block))),
class_name: (_) => /\w+/,
```

Automatically closing a paragraph when a div closes is harder (which in Djot is more general, and is used to close other elements such as code blocks too).

To do this we need an external scanner, which essentially means we need some custom scanner code in C.

## A simple scanner

First, lets ignore nested blocks and try to only replicate matching starting and ending `:::`.

## Arbitrary levels and nested blocks

Something like this may parse...? But I dunno...

```c
static Block *find_block(Scanner *s, BlockType type, uint8_t level) {
  for (size_t i = 0; i < s->open_blocks.size; ++i) {
    Block *b = s->open_blocks.items[i];
    if (b->type == type && b->level == level) {
      return b;
    }
  }
  return NULL;
}

static void dump_stach(Scanner *s) {
  printf("=== Stack size: %zu\n", s->open_blocks.size);
  for (size_t i = 0; i < s->open_blocks.size; ++i) {
    Block *b = s->open_blocks.items[i];
    printf("  %d\n", b->level);
  }
  printf("=== Stack\n");
}

// Remove blocks until 'b' is reached.
// Is inclusive, so will free 'b'!
static void remove_blocks_until(Scanner *s, Block *b) {
  for (;;) {
    Block *top = peek_block(s);
    bool found = top == b;
    // printf("-> removing block %d\n", top->level);
    // TODO should issue a $._block_close token
    // instead of just removing it here...
    // So we need to set some kind of state here instead
    // and pop the topmost block until we reach
    // our target block.
    pop_block(s);
    dump_stach(s);

    // Should always work, size check is just a safeguard.
    if (found || s->open_blocks.size == 0) {
      return;
    }
  }
}

static bool parse_div(Scanner *s, TSLexer *lexer, const bool *valid_symbols) {
  uint8_t colons = 0;
  while (lexer->lookahead == ':') {
    lexer->advance(lexer, false);
    ++colons;
  }

  if (colons < 3) {
    return false;
  }

  // The context could either be a start or an end token.
  // To figure out which we should do, we search through the entire
  // block stack to find if there's an open block somewhere
  // with the same number of colons.
  // If there is, we should close that one, otherwise
  // we start a new div.
  Block *existing = find_block(s, DIV, colons);
  if (existing) {
    lexer->result_symbol = DIV_END;
    remove_blocks_until(s, existing);

    return true;
  } else {
    Block *b = malloc(sizeof(Block));
    b->level = colons;
    b->type = DIV;

    push_block(s, b);
    lexer->result_symbol = DIV_START;

    return true;
  }

  // if (has_block(s)) {
  //   Block *current = peek_block(s);
  //   // We found a matching closing div tag
  //   if (current->type == DIV && current->level == colons) {
  //     pop_block(s);
  //     lexer->result_symbol = DIV_END;
  //     return true;
  //   }
  // }
}
```

## Closing blocks

This can close divs, but cannot close paragraphs:

```js
alias($._block_close, $.block_close),
optional(alias($._div_end, $.div_marker_end))
```

```c
#include "tree_sitter/parser.h"
#include <assert.h>
#include <stdio.h>
#include <string.h>

// Maybe we should implement a growable stack or something,
// but this is probably fine.
#define STACK_SIZE 512

typedef enum { BLOCK_CLOSE, DIV_START, DIV_END, ERROR, UNUSED } TokenType;

typedef enum {
  DIV,
} BlockType;

typedef struct {
  // Level can be either indentation or number of opening/ending symbols.
  // Or it may also be unused.
  uint8_t level;
  BlockType type;
} Block;

typedef struct {
  struct {
    size_t size;
    Block *items[STACK_SIZE];
  } open_blocks;

  // How many $._close_block we should output right now?
  uint8_t blocks_to_close;
  // After we have closed all blocks, what symbol should we output?
  TokenType block_close_final_token;
  uint8_t final_token_width;
} Scanner;

static void push_block(Scanner *s, uint8_t level, BlockType type) {
  Block *b = malloc(sizeof(Block));
  b->level = level;
  b->type = type;
  s->open_blocks.items[s->open_blocks.size++] = b;
}

static void pop_block(Scanner *s) {
  if (s->open_blocks.size > 0) {
    printf("POP\n");
    free(s->open_blocks.items[--s->open_blocks.size]);
  }
}

static bool has_block(Scanner *s) { return s->open_blocks.size > 0; }

static Block *peek_block(Scanner *s) {
  assert(s->open_blocks.size > 0);
  return s->open_blocks.items[s->open_blocks.size - 1];
}

// How many blocks from the top of the stack can we find a matching block?
// If it's directly on the top, returns 1.
// If it cannot be found, returns 0.
static size_t number_of_blocks_from_top(Scanner *s, BlockType type,
                                        uint8_t level) {
  for (size_t i = 0; i < s->open_blocks.size; ++i) {
    Block *b = s->open_blocks.items[i];
    if (b->type == type && b->level == level) {
      return s->open_blocks.size - i;
    }
  }
  return 0;
}

// Remove 'count' blocks from the stack, freeing them.
static void remove_blocks(Scanner *s, size_t count) {
  while (count-- > 0) {
    pop_block(s);
  }
}

static void dump(Scanner *s) {
  printf("=== Stack size: %zu\n", s->open_blocks.size);
  for (size_t i = 0; i < s->open_blocks.size; ++i) {
    Block *b = s->open_blocks.items[i];
    printf("  %d\n", b->level);
  }
  printf("---\n");
  printf("  blocks_to_close: %d\n", s->blocks_to_close);
  printf("  final_token_width: %d\n", s->final_token_width);
  printf("  block_close_final_token: %u\n", s->block_close_final_token);
  printf("===\n");
}

static void close_blocks(Scanner *s, TSLexer *lexer, size_t count,
                         TokenType final, uint8_t final_token_width) {
  printf("CLOSE %zu blocks\n", count);
  s->block_close_final_token = final;
  s->blocks_to_close = count - 1;
  s->final_token_width = final_token_width;
  lexer->result_symbol = BLOCK_CLOSE;
  pop_block(s);
}

static bool parse_div(Scanner *s, TSLexer *lexer, const bool *valid_symbols) {
  uint8_t colons = 0;
  // Because we want to emit a BLOCK_CLOSE token before
  // consuming the `:::` token, we mark the end before advancing
  // to allow us to peek forward.
  lexer->mark_end(lexer);
  while (lexer->lookahead == ':') {
    lexer->advance(lexer, false);
    ++colons;
  }

  if (colons < 3) {
    return false;
  }

  // The context could either be a start or an end token.
  // To figure out which we should do, we search through the entire
  // block stack to find if there's an open block somewhere
  // with the same number of colons.
  // If there is, we should close that one (and all open blocks before),
  // otherwise we start a new div.
  size_t from_top = number_of_blocks_from_top(s, DIV, colons);
  printf("from top: %d\n", from_top);
  if (from_top > 0) {
    close_blocks(s, lexer, from_top, DIV_END, 3);
    dump(s);
    return true;
  } else {
    // We can consume the colons as we start a new div now.
    lexer->mark_end(lexer);
    push_block(s, colons, DIV);
    lexer->result_symbol = DIV_START;
    printf("DIV_START\n");
    dump(s);
    return true;
  }
}

bool tree_sitter_djot_external_scanner_scan(void *payload, TSLexer *lexer,
                                            const bool *valid_symbols) {

  Scanner *s = (Scanner *)payload;

  printf("SCAN\n");
  dump(s);
  printf("? BLOCK_CLOSE %b\n", valid_symbols[BLOCK_CLOSE]);
  printf("? DIV_START %b\n", valid_symbols[DIV_START]);
  printf("? DIV_END %b\n", valid_symbols[DIV_END]);
  printf("current '%c'\n", lexer->lookahead);

  // If we reach oef with open blocks, we should close them all.
  if (lexer->eof(lexer) && s->open_blocks.size > 0) {
    printf("BLOCK_CLOSE eof\n");
    lexer->result_symbol = BLOCK_CLOSE;
    pop_block(s);
    return true;
  }

  if (valid_symbols[BLOCK_CLOSE] && s->blocks_to_close > 0) {
    printf("BLOCK_CLOSE extra\n");
    lexer->result_symbol = BLOCK_CLOSE;
    --s->blocks_to_close;
    pop_block(s);
    return true;
  }
  if (s->blocks_to_close > 0) {
    printf("REJECTED, MUST CLOSE BLOCKS\n");
    // Must close them blocks!
    return false;
  }

  if (s->blocks_to_close == 0 && valid_symbols[s->block_close_final_token]) {
    lexer->result_symbol = s->block_close_final_token;
    s->block_close_final_token = UNUSED;
    while (s->final_token_width--) {
      lexer->advance(lexer, false);
    }
    printf("FINAL TOKEN\n");
    return true;
  }

  if (valid_symbols[DIV_START] || valid_symbols[DIV_END]) {
    return parse_div(s, lexer, valid_symbols);
  }

  return false;
}

void *tree_sitter_djot_external_scanner_create() {
  Scanner *s = (Scanner *)malloc(sizeof(Scanner));
  s->open_blocks.size = 0;
  s->final_token_width = 0;
  s->blocks_to_close = 0;
  s->block_close_final_token = UNUSED;
  // s->open_blocks.items = (Block *)calloc(1, sizeof(Block));
  return s;
}

void tree_sitter_djot_external_scanner_destroy(void *payload) {
  Scanner *s = (Scanner *)payload;
  // printf("%zu", s->open_blocks.size);
  for (size_t i = 0; i < s->open_blocks.size; i++) {
    free(s->open_blocks.items[i]);
  }
  // free(s->open_blocks.items);
  free(s);
}

unsigned tree_sitter_djot_external_scanner_serialize(void *payload,
                                                     char *buffer) {
  Scanner *s = (Scanner *)payload;
  unsigned size = 0;
  buffer[size++] = (char)s->blocks_to_close;
  buffer[size++] = (char)s->block_close_final_token;
  buffer[size++] = (char)s->final_token_width;
  size_t blocks = s->open_blocks.size;
  if (blocks > 0) {
    size_t blocks_size = blocks * sizeof(Block);
    memcpy(&buffer[size], s->open_blocks.items, blocks_size);
    size += blocks_size;
  }

  return size;
}

void tree_sitter_djot_external_scanner_deserialize(void *payload, char *buffer,
                                                   unsigned length) {
  Scanner *s = (Scanner *)payload;
  s->open_blocks.size = 0;
  s->final_token_width = 0;
  s->blocks_to_close = 0;
  s->block_close_final_token = UNUSED;
  if (length > 0) {
    size_t size = 0;
    s->blocks_to_close = (uint8_t)buffer[size++];
    s->block_close_final_token = (TokenType)buffer[size++];
    s->final_token_width = (uint8_t)buffer[size++];

    size_t blocks_size = length - size;
    if (blocks_size > 0) {
      size_t blocks = blocks_size / sizeof(Block);
      memcpy(s->open_blocks.items, &buffer[size], blocks_size);
      s->open_blocks.size = blocks;
    }
  }
}
```

## Closing paragraphs

```js
module.exports = grammar({
  name: "djot",

  // TODO need to escape special characters everywhere
  // maybe we can do this early and automatically skip them in our token logic?

  // Can be directly followed:
  // - Thematic break or fenced block can be followed by paragraph
  // But maybe we already have this?

  // Paragraph can never be interrupted by the start of another block level element
  // Paragraph end: blankline, eof, end of containing block

  // Containing block should automatically close:
  // - Paragraph
  // - Header
  // - Changing list style closes adjacent list of other type
  // - Code block
  // - Raw block
  // - Div

  // Container blocks that can close:
  // - Code block
  // - Raw block
  // - Block quote
  // - Div

  // Link def url can be split into multiple lines

  // Strategy with external scanner:
  // Identify start and end of all blocks.
  //
  // Keep a stack of block level elements to close inside
  // (meaning we need to track all blocks).
  //
  // When something is closed, we should issue a "$._close_block" token
  // that we always match to close all blocks.
  //
  // Need to track paragraphs as well, and paragraphs should close
  // either via $._close_block or blankline or eof.

  extras: (_) => ["\r"],

  // conflicts: ($) => [
  //   [$.paragraph, $.div],
  //   [$._inline_with_newlines, $._close_paragraph],
  // ],

  rules: {
    document: ($) => repeat($._block),

    // Every block contains a newline.
    _block: ($) =>
      choice(
        $._heading,
        // $.list, // Needs external scanner to match indentation!
        // $.pipe_table, // External. Has a caption too that needs to match indent
        // $.footnote, // External, needs to consider indentation level
        $.div,
        // $.codeblock,
        // $.raw_block,
        // $.thematicbreak,
        $.blockquote,
        $.link_reference_definition,
        // $.block_attribute,
        $.paragraph,
        "\n"
      ),

    _heading: ($) =>
      choice(
        $.heading1,
        $.heading2,
        $.heading3,
        $.heading4,
        $.heading5,
        $.heading6
      ),
    heading1: ($) => seq("#", $._gobble_header),
    heading2: ($) => seq(/#{2}/, $._gobble_header),
    heading3: ($) => seq(/#{3}/, $._gobble_header),
    heading4: ($) => seq(/#{4}/, $._gobble_header),
    heading5: ($) => seq(/#{5}/, $._gobble_header),
    heading6: ($) => seq(/#{6}/, $._gobble_header),
    // NOTE because we don't tag the `#` character individually,
    // there's no need to match the beginning `#` of each consecutive line.
    _gobble_header: ($) => seq($._inline_with_newlines, $._eof_or_blankline),

    // I guess we could use an external scanner to allow arbitrary symbols,
    // but this was easier :)
    // div: ($) => choice($._div3, $._div4, $._div5, $._div6, $._div7, $._div8),
    // _div3: ($) => seq(/:{3}/, $._inside_div, /:{3}/),
    // _div4: ($) => seq(/:{4}/, $._inside_div, /:{4}/),
    // _div5: ($) => seq(/:{5}/, $._inside_div, /:{5}/), _div6: ($) => seq(/:{6}/, $._inside_div, /:{6}/),
    // _div7: ($) => seq(/:{7}/, $._inside_div, /:{7}/),
    // _div8: ($) => seq(/:{8}/, $._inside_div, /:{8}/),
    // _inside_div: ($) =>
    //   prec.left(seq(/[ ]*/, optional($.class_name), "\n", repeat($._block))),
    // class_name: (_) => /\w+/,
    div: ($) =>
      seq(
        $.div_marker_start,
        optional($.class_name),
        "\n",
        repeat($._block),
        $._block_close,
        optional(alias($._div_end, $.div_marker_end))
    div_marker_start: ($) =>
      seq($._div_start, optional(seq(/[ ]+/, $.class_name))),
    class_name: (_) => /\w+/,

    // It's fine to let inline gobble up leading `>` for lazy
    // quotes lines.
    blockquote: ($) => seq(">", $._inline_with_newlines, $._eof_or_blankline),

    link_reference_definition: ($) =>
      seq(
        alias($._reference_link_label, $.link_label),
        token.immediate(":"),
        /\s+/,
        $.link_destination,
        $._one_or_two_newlines
      ),
    _reference_link_label: (_) =>
      token(seq("[", token.immediate(/\w+/), token.immediate("]"))),
    link_destination: (_) => /\S+/,

    paragraph: ($) =>
      seq(
        $._inline_with_newlines,
        choice($._eof_or_blankline, $._close_paragraph)
      ),

    _eof_or_blankline: (_) => choice("\0", "\n\n", "\n\0"),
    _one_or_two_newlines: (_) => choice("\0", "\n\n", "\n"),

    _inline: ($) =>
      repeat1(
        choice(
          // $.image,
          // $.autolink,
          // $.verbatim, // Should match ` count
          // $.emphasis,
          // $.strong,
          // $.highlighted,
          // $.superscript,
          // $.subscript,
          // $.insert,
          // $.delete,
          // // Smart punctuation
          // $.math,
          // $.footnote_reference,
          // $.line_break,
          // $.comment,
          // $.symbol,
          // $.raw_inline,
          // $.span,
          // // $.inline_attribute,
          $._link,
          $._text,
          // alias($._text, $.txt)
          " "
        )
      ),
    _inline_with_newlines: ($) => repeat1(prec.left(choice($._inline, /\s/))),

    _link: ($) =>
      choice($.full_reference_link, $.collapsed_reference_link, $.inline_link),

    full_reference_link: ($) => seq($.link_text, $.link_label),
    collapsed_reference_link: ($) => seq($.link_text, token.immediate("[]")),
    inline_link: ($) => seq($.link_text, $.inline_link_destination),

    link_text: ($) => seq("[", $._inline, "]"),

    link_label: ($) => seq("[", $._inline, token.immediate("]")),
    inline_link_destination: (_) => seq("(", /[^\)]+/, ")"),

    _text: (_) => /\S/,
  },

  externals: ($) => [
    $._block_close,
    $._div_start,
    $._div_end,
    $._close_paragraph,

    // Never valid and is used to kill parse branches.
    $._error,
    // Should never be used.
    $._unusued,
  ],
});
```

```c
#include "tree_sitter/parser.h"
#include <assert.h>
#include <stdio.h>
#include <string.h>

// Maybe we should implement a growable stack or something,
// but this is probably fine.
#define STACK_SIZE 512

typedef enum {
  BLOCK_CLOSE,
  DIV_START,
  DIV_END,
  CLOSE_PARAGRAPH,
  ERROR,
  UNUSED
} TokenType;

typedef enum {
  DIV,
} BlockType;

typedef struct {
  // Level can be either indentation or number of opening/ending symbols.
  // Or it may also be unused.
  uint8_t level;
  BlockType type;
} Block;

typedef struct {
  struct {
    size_t size;
    Block *items[STACK_SIZE];
  } open_blocks;

  // How many $._close_block we should output right now?
  uint8_t blocks_to_close;
  // After we have closed all blocks, what symbol should we output?
  TokenType block_close_final_token;
  uint8_t final_token_width;
} Scanner;

static void push_block(Scanner *s, uint8_t level, BlockType type) {
  Block *b = malloc(sizeof(Block));
  b->level = level;
  b->type = type;
  s->open_blocks.items[s->open_blocks.size++] = b;
}

static void pop_block(Scanner *s) {
  if (s->open_blocks.size > 0) {
    // printf("POP\n");
    free(s->open_blocks.items[--s->open_blocks.size]);
  }
}

static bool has_block(Scanner *s) { return s->open_blocks.size > 0; }

static Block *peek_block(Scanner *s) {
  assert(s->open_blocks.size > 0);
  return s->open_blocks.items[s->open_blocks.size - 1];
}

// How many blocks from the top of the stack can we find a matching block?
// If it's directly on the top, returns 1.
// If it cannot be found, returns 0.
static size_t number_of_blocks_from_top(Scanner *s, BlockType type,
                                        uint8_t level) {
  for (size_t i = 0; i < s->open_blocks.size; ++i) {
    Block *b = s->open_blocks.items[i];
    if (b->type == type && b->level == level) {
      return s->open_blocks.size - i;
    }
  }
  return 0;
}

// Remove 'count' blocks from the stack, freeing them.
static void remove_blocks(Scanner *s, size_t count) {
  while (count-- > 0) {
    pop_block(s);
  }
}

static void dump(Scanner *s) {
  printf("=== Stack size: %zu\n", s->open_blocks.size);
  for (size_t i = 0; i < s->open_blocks.size; ++i) {
    Block *b = s->open_blocks.items[i];
    printf("  %d\n", b->level);
  }
  printf("---\n");
  printf("  blocks_to_close: %d\n", s->blocks_to_close);
  printf("  final_token_width: %d\n", s->final_token_width);
  printf("  block_close_final_token: %u\n", s->block_close_final_token);
  printf("===\n");
}

static void close_blocks(Scanner *s, TSLexer *lexer, size_t count,
                         TokenType final, uint8_t final_token_width) {
  // printf("CLOSE %zu blocks\n", count);
  s->block_close_final_token = final;
  s->blocks_to_close = count - 1;
  s->final_token_width = final_token_width;
  lexer->result_symbol = BLOCK_CLOSE;
  pop_block(s);
}

static bool should_close_paragraph(Scanner *s, TSLexer *lexer,
                                   const bool *valid_symbols) {
  // We're only peeking
  // FIXME combine with parse_div
  lexer->mark_end(lexer);

  uint8_t colons = 0;
  // Because we want to emit a BLOCK_CLOSE token before
  // consuming the `:::` token, we mark the end before advancing
  // to allow us to peek forward.
  lexer->mark_end(lexer);
  while (lexer->lookahead == ':') {
    lexer->advance(lexer, false);
    ++colons;
  }

  if (colons < 3) {
    return false;
  }

  size_t from_top = number_of_blocks_from_top(s, DIV, colons);
  return from_top != 0;
}

static bool parse_div(Scanner *s, TSLexer *lexer, const bool *valid_symbols) {
  uint8_t colons = 0;
  // Because we want to emit a BLOCK_CLOSE token before
  // consuming the `:::` token, we mark the end before advancing
  // to allow us to peek forward.
  lexer->mark_end(lexer);
  while (lexer->lookahead == ':') {
    lexer->advance(lexer, false);
    ++colons;
  }

  if (colons < 3) {
    return false;
  }

  // The context could either be a start or an end token.
  // To figure out which we should do, we search through the entire
  // block stack to find if there's an open block somewhere
  // with the same number of colons.
  // If there is, we should close that one (and all open blocks before),
  // otherwise we start a new div.
  size_t from_top = number_of_blocks_from_top(s, DIV, colons);
  // printf("from top: %zu\n", from_top);
  if (from_top > 0) {
    close_blocks(s, lexer, from_top, DIV_END, 3);
    // dump(s);
    return true;
  } else {
    // We can consume the colons as we start a new div now.
    lexer->mark_end(lexer);
    push_block(s, colons, DIV);
    lexer->result_symbol = DIV_START;
    // printf("DIV_START\n");
    // dump(s);
    return true;
  }
}

bool tree_sitter_djot_external_scanner_scan(void *payload, TSLexer *lexer,
                                            const bool *valid_symbols) {

  Scanner *s = (Scanner *)payload;

  // printf("SCAN\n");
  // dump(s);
  // printf("? BLOCK_CLOSE %b\n", valid_symbols[BLOCK_CLOSE]);
  // printf("? DIV_START %b\n", valid_symbols[DIV_START]);
  // printf("? DIV_END %b\n", valid_symbols[DIV_END]);
  // printf("? CLOSE_PARAGRAPH %b\n", valid_symbols[CLOSE_PARAGRAPH]);
  // printf("current '%c'\n", lexer->lookahead);

  if (valid_symbols[CLOSE_PARAGRAPH] &&
      should_close_paragraph(s, lexer, valid_symbols)) {
    lexer->result_symbol = CLOSE_PARAGRAPH;
    return true;
  }

  // If we reach oef with open blocks, we should close them all.
  if (lexer->eof(lexer) && s->open_blocks.size > 0) {
    // printf("BLOCK_CLOSE eof\n");
    lexer->result_symbol = BLOCK_CLOSE;
    pop_block(s);
    return true;
  }

  if (valid_symbols[BLOCK_CLOSE] && s->blocks_to_close > 0) {
    // printf("BLOCK_CLOSE extra\n");
    lexer->result_symbol = BLOCK_CLOSE;
    --s->blocks_to_close;
    pop_block(s);
    return true;
  }
  if (s->blocks_to_close > 0) {
    // printf("REJECTED, MUST CLOSE BLOCKS\n");
    // Must close them blocks!
    return false;
  }

  if (s->blocks_to_close == 0 && valid_symbols[s->block_close_final_token]) {
    lexer->result_symbol = s->block_close_final_token;
    s->block_close_final_token = UNUSED;
    while (s->final_token_width--) {
      lexer->advance(lexer, false);
    }
    // printf("FINAL TOKEN\n");
    return true;
  }

  if (valid_symbols[DIV_START] || valid_symbols[DIV_END]) {
    return parse_div(s, lexer, valid_symbols);
  }

  return false;
}

void *tree_sitter_djot_external_scanner_create() {
  Scanner *s = (Scanner *)malloc(sizeof(Scanner));
  s->open_blocks.size = 0;
  s->final_token_width = 0;
  s->blocks_to_close = 0;
  s->block_close_final_token = UNUSED;
  // s->open_blocks.items = (Block *)calloc(1, sizeof(Block));
  return s;
}

void tree_sitter_djot_external_scanner_destroy(void *payload) {
  Scanner *s = (Scanner *)payload;
  // printf("%zu", s->open_blocks.size);
  for (size_t i = 0; i < s->open_blocks.size; i++) {
    free(s->open_blocks.items[i]);
  }
  // free(s->open_blocks.items);
  free(s);
}

unsigned tree_sitter_djot_external_scanner_serialize(void *payload,
                                                     char *buffer) {
  Scanner *s = (Scanner *)payload;
  unsigned size = 0;
  buffer[size++] = (char)s->blocks_to_close;
  buffer[size++] = (char)s->block_close_final_token;
  buffer[size++] = (char)s->final_token_width;
  size_t blocks = s->open_blocks.size;
  if (blocks > 0) {
    size_t blocks_size = blocks * sizeof(Block);
    memcpy(&buffer[size], s->open_blocks.items, blocks_size);
    size += blocks_size;
  }

  return size;
}

void tree_sitter_djot_external_scanner_deserialize(void *payload, char *buffer,
                                                   unsigned length) {
  Scanner *s = (Scanner *)payload;
  s->open_blocks.size = 0;
  s->final_token_width = 0;
  s->blocks_to_close = 0;
  s->block_close_final_token = UNUSED;
  if (length > 0) {
    size_t size = 0;
    s->blocks_to_close = (uint8_t)buffer[size++];
    s->block_close_final_token = (TokenType)buffer[size++];
    s->final_token_width = (uint8_t)buffer[size++];

    size_t blocks_size = length - size;
    if (blocks_size > 0) {
      size_t blocks = blocks_size / sizeof(Block);
      memcpy(s->open_blocks.items, &buffer[size], blocks_size);
      s->open_blocks.size = blocks;
    }
  }
}
```

# Adding highlights

## Using our grammar with Neovim
